# -*- coding: utf-8 -*-
"""sentimental Analysis .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11pT-5GZSOwozlEeWfgNR1ZdytA1w-X_k
"""

import pandas as pd

TweetID_file=pd.read_csv('/content/sample_data/yelp_labelled.txt', sep="\t", header=None, names=['text','category'])

corpus=pd.DataFrame(TweetID_file,columns= ['text','category'])

corpus.head()

#get indpendent features 
X=corpus.drop('category',axis=1)
X

corpus['text'][6]

from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
from nltk.tokenize import word_tokenize
import re
ps=PorterStemmer()

import nltk
nltk.download('stopwords')
nltk.download('punkt')

messages=[]
for i in range(0,len(corpus)):
    review=re.sub('[^a-zA-Z]',' ',corpus['text'][i])
    review=review.lower()
    text_tokens = word_tokenize(review)
    review=[ps.stem(word) for word in text_tokens if not  word in stopwords.words('english')]
    print(review)
    review=' '.join(review)
    messages.append(review)



y=corpus['category']
y.head()

from sklearn.feature_extraction.text import CountVectorizer
countVect = CountVectorizer(max_features=1500,lowercase=True, analyzer='word',
 ngram_range=(1,2))
count_vect = countVect.fit_transform(messages).toarray()
count_vect.shape

from sklearn.feature_extraction.text import TfidfVectorizer
tfidf = TfidfVectorizer(max_features=1500,lowercase=True, analyzer='word',
 ngram_range=(1,2),max_df=0.8)
train_vect = tfidf.fit_transform(messages).toarray()
train_vect.shape

from sklearn.model_selection import train_test_split

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(count_vect, y, test_size=0.33, random_state=0)

X_train, X_test, y_train, y_test = train_test_split(count_vect, y, test_size=0.33, random_state=0)

from sklearn.linear_model import LogisticRegression

from sklearn.naive_bayes import GaussianNB
classifier = GaussianNB()
classifier.fit(X_train, y_train)

y_pred = classifier.predict(X_test)

y_test.shape[0]

print('accuracy -> {}'.format(sum(y_pred == y_test) / y_test.shape[0]))

from sklearn.metrics import  confusion_matrix, accuracy_score

print(confusion_matrix(y_test,y_pred))

print(accuracy_score(y_test, y_pred))